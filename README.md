# Australian Hospital SeparationsÂ ETLÂ & Streamlit Dashboard

## Overview
This project delivers a **fullyâ€‘automated data pipeline** that downloads publiclyâ€‘available hospitalâ€‘separation tables from the Australian Institute of Health & Welfare (AIHW), cleans and normalises them into a relational schema, and then serves an **interactive Streamlit dashboard** with rich visual analytics and autoâ€‘generated insights.

## Project GoalÂ ğŸ¯
Build a **fullyâ€“automated publicâ€‘health data platform** that:
1. Scrapes the latest _Admittedâ€‘Patientâ€‘Care_ tables published by AIHW.  
2. Cleans & normalises the spreadsheets into tidy **staging**/**clean** tables in PostgreSQL.  
3. Serves an interactive **Streamlit** dashboard (7 graphsÂ + profiling) for rapid exploratory analysis.

* **ETL (Python)**Â â€“â€¯Webâ€‘scrapes/ingests Excel workbooks, detects headers on the fly, removes noise, converts values to numeric, and writes two tables to PostgreSQL:
  * `staging_admissions`Â Â Â â†³ raw tidy rows
  * `clean_admissions`Â Â Â Â â†³ aggregated by every categorical dimension
* **Analytics (Streamlit)**Â â€“â€¯When you launch the app it pulls from `clean_admissions` (or falls back to `staging_admissions` if the former is empty) and renders **7 productionâ€‘ready visuals** (bar, line, pie, heatâ€‘map, treemap, choropleth, boxâ€‘plot) plus keyâ€‘takeaway text.
* **Optional Dataâ€‘Profiling** â€“â€¯A oneâ€‘click pandasâ€‘profiling report for deeper EDA (gracefully skipped if the `numba`/`visions` dependency chain fails under PythonÂ 3.12).

## Features
- ğŸ“¥ **Robust Extraction** â€“ Dynamic header detection; supports new AIHW workbook versions without code edits.
- ğŸ§¹ **Smart Transformation** â€“ Autoâ€‘deduplicates column names, harmonises categories, coerces numeric types.
- ğŸ—„ **PostgreSQL Load** â€“ Idempotent writes using SQLAlchemy with automatic upserts.
- ğŸ“Š **Interactive Dashboard** â€“ Sidebar filters on every categorical column, realâ€‘time Plotly charts, AUS map.
- ğŸ—’ **Insight Generator** â€“ Tiny NLP summary highlights top states, categories, YoY change.
- ğŸ§® **Optional Profiling** â€“ Generates an HTML report inside Streamlit.

## StackÂ âš™ï¸
| Layer | Tech | Notes |
|-------|------|-------|
| Orchestration | _oneâ€‘shotÂ script_ (`main.py`) | Simple cron/CI friendly |
| Extraction | `requests`, `BeautifulSoup` | Finds `*-tablesâ€‘access.xlsx` links |
| Transformation | `pandas`, `openpyxl` | Dynamic header detection, robust melt, dtype harmonisation |
| Load | `SQLAlchemy â†’ PostgreSQL` | `staging_admissions` & `clean_admissions` |
| VizÂ /Â App | `Streamlit`, `PlotlyÂ Express` | 7 widgets, autoâ€‘insights, optional `ydataâ€‘profiling` |
| Packaging | `pipxÂ venv`, `.env` | `DB_URL` env var expected |

---

## Prerequisites
| Tool | Version | Notes |
|------|---------|-------|
| **Python** | 3.9Â â€“Â 3.11 recommended | 3.12 works but skip profiling or pin `numba<0.59` |
| **PostgreSQL** | â‰¥Â 12 | Any connection string supported by SQLAlchemy |
| **AIHW Access** | None | Data is public; no API key required |

## Installation
```bash
# 1Â â€”Â Clone
git clone https://github.com/yourâ€‘org/aihwâ€‘hospitalâ€‘etl.git
cd aihwâ€‘hospitalâ€‘etl

# 2Â â€”Â Virtualâ€‘env
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate

# 3Â â€”Â Dependencies
pip install -r requirements.txt

# 4Â â€”Â Environment
cp .env.example .env  # then edit
```
### .env
```
DB_URL=postgresql+psycopg2://user:pass@localhost:5432/health
```

## Initialising the Database
No manual DDL is needed; the ETL script will create both tables if they do not exist. Optionally seed permissions & indices with `schema.sql`.

## Usage ğŸš€
### 1.Â Run the ETL
```bash
python etl.py
# âœ Extracted 314Â 672 rowsÂ â€“ loading â€¦
# âœ…Â ETL completed.
```
### 2.Â Launch the Dashboard
```bash
streamlit run streamlit_app.py
```
The app opens at <http://localhost:8501>.

## ProjectÂ Structure ğŸ“‚
```
aihwâ€‘hospitalâ€‘etl/
â”œâ”€â”€ etl.py              # Extractâ€‘Transformâ€‘Load pipeline
â”œâ”€â”€ streamlit_app.py    # Dashboard & insights
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ .env.example        # Env vars template
â”œâ”€â”€ schema.sql          # Optional indices / grants
â””â”€â”€ README.md           # This file
```

## DataÂ Model
### staging_admissions
| Column | Type | Description |
|--------|------|-------------|
| `year` | INT | Financial yearÂ (e.g.Â 2023) |
| `state` | TEXT | AUS state code (NSW,Â VIC â€¦) |
| `category` | TEXT | ICDâ€‘10 chapter or other grouping |
| `principal_diagnosis` | TEXT | Detailed diagnosis (if available) |
| `_â€¦dynamic dimsâ€¦_` | TEXT | Other categorical dimensions (care_type, etc.) |
| `separations` | NUMERIC | Rate perÂ 1â€¯000 population |

### clean_admissions
Same columns but **aggregated** (`GROUPÂ BY year,Â state,Â *allÂ categoricals* â†’ SUM(separations)`).

## Running in Production
- **Scheduler**: Hook `python etl.py` in cron/Airflow for monthly refresh.
- **Docker**: Copy the sample `Dockerfile`/`dockerâ€‘compose.yml` for containerised deployment.
- **Metrics**: The app logs to stdout; pair with Prometheus/Grafana if needed.

## Troubleshooting
| Issue | Fix |
|-------|-----|
| "DB_URL env var not set" | Export `DB_URL` or add to `.env`. |
| Duplicate columns error | ETL now autoâ€‘dedups; reâ€‘run ETL. |
| Profiling fails under Pyâ€¯3.12 | `pip install "numba<0.59"`Â or unâ€‘tick the profiling button. |

## FutureÂ Enhancements
- Autoâ€‘download GeoJSON for precise choropleth maps.
- Great Expectations dataâ€‘validation checkpoints.
- CI/CD workflow (GitHubÂ Actions) to lint, test, and deploy.

## License
MIT

## Acknowledgements
* **AIHW** â€“ Source of open hospitalâ€‘separation data.
* **Streamlit & Plotly** â€“ Rapid interactive visualisation.
* **pandasâ€‘profiling** â€“ Quick EDA inside the browser.